---
engine: knitr
---

# Concluding remarks {#sec-concluding-remarks}

**Required material**

- Read *Five ways to fix statistics*, [@Leek2017]
- Read *Ten computer codes that transformed science*, [@Perkel2021]
- Read *Learning from Data Journeys*, [@Leonelli2020]
- Watch *Science as Amateur Software Development*, [@scienceassoftwaredev]

## Concluding remarks

There is an old saying, something along the lines of "may you live in interesting times". Possibly every generation feels this way, but we sure live in interesting times. In this book, we have covered some essential skills that would allow you to tell stories with data. And we are just getting started.

In less than a generation, data science has gone from something that barely existed, to a defining part of academia and industry. The extent and pace of this change has many implications for those learning data science. For instance, it may imply that one should not just make decisions that optimize for what data science looks like right now, but also what could happen. While that is a little difficult, that is also one of the things that makes data science so exciting. That might mean choices like:

- taking courses on fundamentals, not just fashionable applications;
- reading books, not just whatever is trending; and
- trying to be at the intersection of at least a few different areas, rather than hyper-specialized.

One of the most exciting times when you learn data science is realizing that you just love playing with data. A decade ago, this did not fit into any particular department, these days it fits into almost any of them. Data science needs diversity, both in terms of approaches and applications. It is increasingly the most important work in the world and hegemonic approaches have no place. It is just such an exciting time to be enthusiastic about data and able to build things.

The central thesis of this book has been that a revolution is needed in data science, and we have proposed one view of what it could look like. This revolution builds on the long history of statistics, takes from computer science, and draws on other disciplines as needed, but is centered around reproducibility, workflows, respect, and data. Data science began by drawing on a variety of disciplines, but it is no longer at the intersection on these, instead, it has the maturity to stand on its own.

This book has been a reimagining of what data science is, and what it could be. In @sec-introduction we provided an informal definition of data science, but having built a foundation, it is time to revisit this. We consider data science to be the process of developing and applying a principled, tested, reproducible, end-to-end workflow, that focuses on quantitative measures in and of themselves, and to explore questions. Excellence in data science creates lasting understanding of the world.

## Some issues

There are many issues that are outstanding as we think about data science. They are not the type of issues that have a definitive answer one way or the other. Instead they are questions to be explored and played with. This work will move the discipline forward and, more importantly, help us tell better stories about the world. Here we detail some of them most pressing concerns.

**1. How do we write tests for data science?**

One thing that computer scientists know is the importance of unit and functional tests. One of the innovations of this book has been to integrate these throughout the data science workflow, but this, like the first iteration of anything, needs considerable innovation and development. 

It is clear that we need to thoroughly integrate testing through data science, but it is far less clear what this should look like, how we should do this, and what the end-state is. What does it mean to have well-tested code in data science? What do these tests look like? How are they written? The extensive use of simulation in statistics, which data science has adopted, has provided us with some foundation, but there is an enormous amount of work and investment that is needed.

**2. What happened to the machine learning revolution?**

It is now clear that the machine learning, sometimes inappropriately termed "AI" [@stopcallingitallai], revolution was oversold. In the social sciences, we have yet to see a convincing application of machine learning methods, which are designed for prediction, to a social sciences problem where what we care about is understanding. 

Some of this is a disdain for data, which has hamstrung AI applications. For instance, there is evidence that misapplied AI may have caused unnecessary death during the pandemic, partly due to a lack of focus on the data [@heaven2021].

The current situation is untenable where folks, especially those in fields that have been historically female, are made to feel inferior even though their results are no worse. And this means that any method that can conceivably be marketed as AI is being overfunded, at the expense of methods that may work better.

**3. What do we do about p-values and power?**

While we have argued that data science is its own discipline, we must be careful to not repeat the mistakes of economics, and continue to learn statistics from statisticians, computer science from computer scientists, etc. This is most clear in the case of p-values, which we have not made much of in this book, but which mistakenly dominant analysis even though statisticians have warned about their misapplication for decades.

The issue with not learning statistics from statisticians, is that it can become a recipe that is blindly followed, because that is the easiest way to teach it, even though that is not how statisticians do statistics. We see this, too, in conversations about the related concept of power, as though there is one appropriate level that we need to meet. 

Many people think that statistics is a recipe to be followed. They think that because that is how they are trained, especially in social sciences like political science and economics, and that's what is rewarded. But that is not what these methods are. Instead, statistics is a collection of different instruments that let us look at our data in a certain way. Data science must remain deeply connected to these other disciplines even as we develop our own.

**4. How do we teach data science?**

We are beginning to start to have agreement on what the foundations of data science are. It involves computational thinking, concern for sampling, statistics, graphics, Git/GitHub, SQL, command line, comfort with messy data, comfort across a few languages including R and Python. But we have very little agreement on how best to teach it. Partly this is because data science instructors often come different fields, but also it is also partly a difference in resources and priorities.

**5. What is happening at the data cleaning and preparation stage?**

We basically do not have a good understanding how much any of this matters. @huntington2021influence showed that hidden research decisions have a big effect on subsequent estimates, sometimes greater than the standard errors. Such findings invalidate claims. We need much more investigation of how these early stages of the data science workflow affect the conclusions.

**6. Constituent parts?**

What role do the constituent parts of data science, especially statistics and CS play? How does it relate to, and interact with, econometrics, applied statistics, computational social science, etc?

**7. Names**

One of the crowning achievements of biology, is the binomial nomenclature, which is the formal systematic approach to names, established by Carolus Linnaeus, the eighteenth-century physician [@morange, p. 81]. Each species is named using two words with Latin grammatical form: the first is its genus, and the second is an adjective to characterize the species. As discussed in @sec-clean-and-prepare, names are a large source of friction and a generalized approach is needed in data science that we can all agree on.

**8. Culture**

How do we ensure that data science takes the best bits from the cultures of other disciplines, and builds an inclusive culture?


## Next steps

This book has covered much ground, and while we are toward the end of it, as the butler Stevens is told in the novel *The Remains of the Day* [@ishiguro]:

> The evening's the best part of the day. You've done your day's work. Now you can put your feet up and enjoy it.

Chances are there are aspects that you want to explore further, building on the foundation that you have established. If so, then the book has accomplished its aim.

If you were new to data science at the start of this book, then the next step would be to backfill that which was skipped over. Begin with *Data Science: A First Introduction* [@timbersandfriends]. After that, you should learn more about R in terms of data science by going through *R for Data Science* [@r4ds]. To deepen your understanding of R itself, go next to *Advanced R* [@advancedr].

To learn more about causality start with *Causal Inference: The Mixtape* [@Cunningham2021] and *The Effect: An Introduction to Research Design and Causality* [@theeffect].

If you are interested to learn more about statistics, then begin with *Statistical Rethinking: A Bayesian Course with Examples in R and Stan* [@citemcelreath]. Then backfill with *Bayes Rules! An Introduction to Bayesian Modeling with R* [@bayesrules] and solidify the foundation with *Bayesian Data Analysis* [@bda]. And it would be worthwhile to bolster some of the probability foundations that we have skimmed over around with *All of Statistics* [@wasserman].

There is only one next natural step if you are interested in learning more about machine learning and that is *An Introduction to Statistical Learning* [@islr] followed by *The Elements of Statistical Learning* [@esl]. After that, learn how to implement it all with *Tidy Modeling with R* [@tidymodelingwithr].

If you are interested in sampling, then the next book to turn to is *Sampling: Design and Analysis* [@lohr]. To deepen your understanding of surveys and experiments, go next to *Field Experiments: Design, Analysis, and Interpretation* [@fieldexperiments] in combination with *Trustworthy online controlled experiments* [@kohavi].

For developing better data visualization skills, begin by turning to *Data Sketches* [@datasketches] and *Data Visualization* [@healyviz], but then after that, develop strong foundations, such as *The Grammar of Graphics* [@grammarofgraphics]. 

And finally, for writing, it would be best to turn inward. Force yourself to write and publish every day for a month. Then do it again and again. You will get better. That said, there are some useful books, including *Working* [@caroonworking] and *On Writing: A Memoir of the Craft* [@stephenking].

We often hear the phrase let the data speak. Hopefully by this point you understand that never happens. All that we can do is to acknowledge that we are the ones using data to tell stories, and strive and seek to make them worthy.

> It was her voice that made  
> The sky acutest at its vanishing.  
> She measured to the hour its solitude.  
> She was the single artificer of the world  
> In which she sang. And when she sang, the sea,  
> Whatever self it had, became the self  
> That was her song, for she was the maker.
> 
> "The Idea of Order at Key West", [@wallacestevens]
